# ğŸ¤ AI Verbal Communication Trainer  
## A Speech Evaluation and Training Tool Powered by Open-Source LLMs  

### ğŸ“Œ Overview  
This project is an **AI-powered verbal communication trainer** that helps users enhance their **public speaking, storytelling, and conflict resolution skills** through structured AI-driven feedback.  

It uses **Gradio** for the web interface, **Whisper** for speech-to-text conversion, and the **Falcon-7B-Instruct** model with **4-bit quantization** for speech analysis.  

---

## ğŸš€ Features  

âœ… **Chat & Voice Interaction** â€“ Engage with AI via text or voice with real-time feedback.  
âœ… **Speech Training Modules** â€“ Improve **impromptu speaking, storytelling, and conflict resolution** skills.  
âœ… **Presentation Assessment** â€“ AI evaluates **clarity, structure, pacing, and confidence**.  
âœ… **Speech Tone Analysis** â€“ Detects **confidence, vocal variation, and filler words**.  
âœ… **Progress Tracking** â€“ Stores user scores in JSON to track improvements over time.  

---

## ğŸ› ï¸ Technologies Used  

- **Falcon-7B-Instruct (4-bit Quantization)** â€“ Powers the speech evaluation system.  
- **Whisper (OpenAI)** â€“ Converts **voice input to text** for analysis.  
- **Gradio** â€“ Provides a **user-friendly web interface**.  
- **JSON Storage** â€“ Tracks **user progress** over multiple sessions.  
- **Python (Transformers, PyTorch, NumPy, OpenAI Whisper)** â€“ For **NLP, speech processing, and AI inference**.  

---

## ğŸ“‚ Project Structure  

ğŸ“¦ **AI Verbal Communication Trainer**  
- ğŸ“‚ **output/** â€“ Contains screenshots & demo results.  
- ğŸ“œ **ai_speech.ipynb** â€“ Jupyter Notebook with AI logic.  
- ğŸ“œ **training_prompts.json** â€“ Predefined training prompts for speech tasks.  
- ğŸ“œ **README.md** â€“ Project Documentation.

---

## ğŸ“Œ Model Selection  

I chose **Falcon-7B-Instruct** with **4-bit quantization** for this project due to its efficiency and strong instruction-following capabilities.  

### ğŸ”¹ **Why Falcon-7B-Instruct?**  
- **Optimized for structured feedback** â€“ Ideal for speech evaluation and coaching.  
- **Balanced performance & compute efficiency** â€“ Outperforms many models in instruction-tuned tasks while being lighter than LLaMA-13B.  
- **Open-source & community-backed** â€“ Ensures flexibility and ongoing improvements.  

### ğŸ”¹ **Why 4-bit Quantization?**  
- **Lower memory usage** â€“ Runs on consumer-grade GPUs.  
- **Faster inference** â€“ Reduces latency without significant accuracy loss.  

This choice provides **high-quality speech analysis** without requiring heavy computational resources. ğŸš€

---

## ğŸš€ Happy Speaking! ğŸ¤  



